from pyspark.sql import SparkSession
import os

# âœ… Set JAVA_HOME here
os.environ["JAVA_HOME"] = "C:\\Program Files\\Eclipse Adoptium\\jdk-17.0.15.6-hotspot"

# âœ… Optional: Update PATH too if needed (uncommon, but safe)
os.environ["PATH"] = os.environ["JAVA_HOME"] + "\\bin;" + os.environ["PATH"]

# ğŸš€ Initialize Spark
spark = SparkSession.builder \
    .appName("myfirstapp") \
    .getOrCreate()

# ğŸ§¾ Sample data
data = [("nagendra", 30), ("Aryan", 28)]
columns = ["Name", "Age"]

# ğŸ” Create DataFrame and show
df = spark.createDataFrame(data, columns)
df.show()

# ğŸ§¹ Stop Spark
spark.stop()
